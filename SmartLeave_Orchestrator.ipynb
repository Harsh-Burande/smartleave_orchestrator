{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXi6Qqcs+U7qZahVqLY7uG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harsh-Burande/smartleave_orchestrator/blob/main/SmartLeave_Orchestrator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# gemini_key = \"AIzaSyDFqi5EVBS1UJuGjKOMq6E2e-WRaBCfGM4\"\n",
        "# NGROK_TOKEN = \"36TiRiENjPUlO8uo6FM1bls4QCB_4AjAyFcDWQdbL8bCgLy5X\"\n",
        "# n8n_prod_url = https://leaverequestn8n.app.n8n.cloud/webhook/smartleave"
      ],
      "metadata": {
        "id": "Bi-_ahtT8YoV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "Df-4Z9prMm5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# MASTER SETUP: Install all required packages\n",
        "# -----------------------------\n",
        "!pip install --quiet streamlit\n",
        "!pip install --quiet pyngrok\n",
        "!pip install --quiet python-dotenv\n",
        "!pip install --quiet google-generativeai\n",
        "\n",
        "\n",
        "\n",
        "# Kill any previous ngrok or streamlit running in background\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n"
      ],
      "metadata": {
        "id": "vtq4T_V_Mp5C",
        "collapsed": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import google.generativeai as genai\n",
        "\n",
        "# genai.configure(api_key=\"AIzaSyDFqi5EVBS1UJuGjKOMq6E2e-WRaBCfGM4\")\n"
      ],
      "metadata": {
        "id": "uC2LjvpmWFNM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini API key\n"
      ],
      "metadata": {
        "id": "poiikrZ6D4Q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "GEMINI_API_KEY = AIzaSyCscPZKrhzSH27noKJyuNxMqoAUkMxtf2I"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBa1iMxuA7gY",
        "outputId": "1cfb3581-5fb0-40b4-b71b-d1d16c70cd5a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTJtRaQjBs50",
        "outputId": "7492f12a-dfab-42dc-e082-d03ba9d29054"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".  ..  .config\t.env  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getenv(\"GEMINI_API_KEY\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5VOoc25DTs4",
        "outputId": "82c17210-e963-4ffd-e3b9-5e3ab8b87a8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extra\n"
      ],
      "metadata": {
        "id": "8kdd_eTYeKMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '1,120p' .env\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62M_LHcDD76_",
        "outputId": "0d953542-21d5-4610-c2dc-43db48e536c2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GEMINI_API_KEY = AIzaSyCscPZKrhzSH27noKJyuNxMqoAUkMxtf2I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls -la\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQUz1PGdEPe3",
        "outputId": "5a210f19-5292-4275-9636-6865f7a56c87"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "total 20\n",
            "drwxr-xr-x 1 root root 4096 Dec 31 06:07 .\n",
            "drwxr-xr-x 1 root root 4096 Dec 31 06:06 ..\n",
            "drwxr-xr-x 4 root root 4096 Dec 11 14:34 .config\n",
            "-rw-r--r-- 1 root root   57 Dec 31 06:07 .env\n",
            "drwxr-xr-x 1 root root 4096 Dec 11 14:34 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# If .env is in current dir:\n",
        "load_dotenv()\n",
        "\n",
        "# If not, give the full path, e.g. load_dotenv('/content/.env')\n",
        "# load_dotenv('/content/.env')\n",
        "\n",
        "print(\"PWD:\", os.getcwd())\n",
        "print(\"ENV FILE CONTENT PREVIEW:\")\n",
        "!sed -n '1,120p' .env\n",
        "print(\"GEMINI_API_KEY =\", os.getenv(\"GEMINI_API_KEY\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAyVkKNzEQOs",
        "outputId": "5088ce68-da53-41e7-e54c-d9e53c2e787b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWD: /content\n",
            "ENV FILE CONTENT PREVIEW:\n",
            "GEMINI_API_KEY = AIzaSyCscPZKrhzSH27noKJyuNxMqoAUkMxtf2I\n",
            "GEMINI_API_KEY = AIzaSyCscPZKrhzSH27noKJyuNxMqoAUkMxtf2I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. verify getenv directly\n",
        "# import os\n",
        "# print(\"Direct getenv:\", bool(os.getenv(\"GEMINI_API_KEY\")), os.getenv(\"GEMINI_API_KEY\")[:6] + \"...\" if os.getenv(\"GEMINI_API_KEY\") else None)\n",
        "\n",
        "# # 2. verify backend module reload sees it (backend.ai_extractor should call load_dotenv())\n",
        "# import importlib\n",
        "# import backend.ai_extractor as ai\n",
        "# importlib.reload(ai)\n",
        "# print(\"Backend module mode (exists):\", hasattr(ai, \"extract_leave_data\"))\n",
        "# print(\"Backend sees GEMINI_API_KEY from os.getenv inside notebook:\", os.getenv(\"GEMINI_API_KEY\") is not None)\n"
      ],
      "metadata": {
        "id": "LTqelb67EmOU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google import genai\n",
        "    print(\"Gemini SDK import OK\")\n",
        "except Exception as e:\n",
        "    print(\"Gemini SDK import FAILED:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vh8ibgAbEtNR",
        "outputId": "062c261a-746b-4925-f01e-b7a879cb74a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini SDK import OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from backend.ai_extractor import extract_leave_data\n",
        "\n",
        "# sample = \"My name is Ravi. I need leave from 12/12/2025 to 14/12/2025 because I have a family wedding. I will attach photos. This is urgent.\"\n",
        "# res = extract_leave_data(sample)\n",
        "# print(res)\n"
      ],
      "metadata": {
        "id": "91HQIVNME1eF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from backend.ai_extractor import extract_leave_data\n",
        "# sample = \"My name is Ravi. I need leave from 12/12/2025 to 14/12/2025 because I have a family wedding. I will attach photos. This is urgent.\"\n",
        "# res = extract_leave_data(sample)\n",
        "# print(res)                  # what you already did\n",
        "# print(\"mode:\", res.get(\"mode\"))\n",
        "# print(\"keys:\", sorted(res.keys()))\n"
      ],
      "metadata": {
        "id": "FU1AwRnaFBWY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backend AI\n"
      ],
      "metadata": {
        "id": "SWpojDPz80qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!mkdir -p backend\n"
      ],
      "metadata": {
        "id": "noNlX_6a84Yd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile backend/ai_extractor.py\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from datetime import datetime\n",
        "from typing import Optional, Dict\n",
        "\n",
        "# load .env in dev\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "SDK_AVAILABLE = True\n",
        "try:\n",
        "    from google import genai\n",
        "except Exception:\n",
        "    SDK_AVAILABLE = False\n",
        "\n",
        "# -------------------------\n",
        "# Local rule-based extractor\n",
        "# -------------------------\n",
        "def _parse_date(d: str) -> Optional[str]:\n",
        "    if not d:\n",
        "        return None\n",
        "    d = d.replace(\"-\", \"/\")\n",
        "    for fmt in (\"%d/%m/%Y\", \"%d/%m/%y\"):\n",
        "        try:\n",
        "            return datetime.strptime(d, fmt).date().isoformat()\n",
        "        except ValueError:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "def _basic_extract(text: str) -> Dict:\n",
        "    tl = text.lower()\n",
        "    name = None\n",
        "    m_name = re.search(r\"(my name is|i am)\\s+([A-Za-z ]+)\", text, re.IGNORECASE)\n",
        "    if m_name:\n",
        "        name = m_name.group(2).strip(\" ,.\")\n",
        "    date_strings = re.findall(r\"\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\", text)\n",
        "    start_date = _parse_date(date_strings[0]) if len(date_strings) >= 1 else None\n",
        "    end_date   = _parse_date(date_strings[1]) if len(date_strings) >= 2 else None\n",
        "    total_days = None\n",
        "    if start_date and end_date:\n",
        "        try:\n",
        "            d1 = datetime.fromisoformat(start_date)\n",
        "            d2 = datetime.fromisoformat(end_date)\n",
        "            total_days = (d2 - d1).days + 1\n",
        "        except Exception:\n",
        "            total_days = None\n",
        "\n",
        "    leave_type = None\n",
        "    if any(w in tl for w in [\"fever\", \"sick\", \"ill\", \"doctor\", \"infection\"]):\n",
        "        leave_type = \"Sick Leave\"\n",
        "    elif any(w in tl for w in [\"family function\", \"marriage\", \"wedding\", \"ceremony\", \"engagement\", \"casual\"]):\n",
        "        leave_type = \"Casual Leave\"\n",
        "    elif any(w in tl for w in [\"vacation\", \"trip\", \"holiday\", \"travel\"]):\n",
        "        leave_type = \"Paid Leave\"\n",
        "    elif \"work from home\" in tl or \"wfh\" in tl:\n",
        "        leave_type = \"Work From Home\"\n",
        "    else:\n",
        "        leave_type = \"Other\"\n",
        "\n",
        "    m_reason = re.search(r\"(because|as|since)\\s+(.+)\", text, re.IGNORECASE)\n",
        "    reason = m_reason.group(2).strip(\" .\") if m_reason else text.strip()\n",
        "\n",
        "    urgency = \"medium\"\n",
        "    if any(w in tl for w in [\"urgent\", \"immediately\", \"asap\"]):\n",
        "        urgency = \"high\"\n",
        "    elif any(w in tl for w in [\"whenever possible\", \"if possible\", \"no hurry\"]):\n",
        "        urgency = \"low\"\n",
        "\n",
        "    has_supporting_document = any(\n",
        "        w in tl for w in [\"attachment\", \"report\", \"certificate\", \"prescription\", \"document\"]\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"employee_name\": name,\n",
        "        \"start_date\": start_date,\n",
        "        \"end_date\": end_date,\n",
        "        \"total_days\": total_days,\n",
        "        \"leave_type\": leave_type,\n",
        "        \"reason\": reason,\n",
        "        \"urgency\": urgency,\n",
        "        \"has_supporting_document\": has_supporting_document,\n",
        "        \"mode\": \"local_rule_engine\"\n",
        "    }\n",
        "\n",
        "# -------------------------\n",
        "# Gemini wrapper\n",
        "# -------------------------\n",
        "EXPECTED_KEYS = [\n",
        "    \"employee_name\",\n",
        "    \"start_date\",\n",
        "    \"end_date\",\n",
        "    \"total_days\",\n",
        "    \"leave_type\",\n",
        "    \"reason\",\n",
        "    \"urgency\",\n",
        "    \"has_supporting_document\",\n",
        "    \"mode\"\n",
        "]\n",
        "\n",
        "def _force_json_prompt(text: str) -> str:\n",
        "    system = (\n",
        "        \"You are a JSON-output assistant. Given an employee leave description, \"\n",
        "        \"produce only valid JSON (no explanation) with exactly these keys: \"\n",
        "        f\"{EXPECTED_KEYS}. Date values should be ISO YYYY-MM-DD or null. \"\n",
        "        \"leave_type should be one of: 'Sick Leave','Casual Leave','Paid Leave','Work From Home','Other'. \"\n",
        "        \"urgency must be one of: 'low','medium','high'. \"\n",
        "        \"has_supporting_document must be true or false. \"\n",
        "        \"mode should be 'gemini'. \"\n",
        "        \"Make values concise. Return a single JSON object and nothing else.\"\n",
        "    )\n",
        "    user = f\"Leave description:\\n\\\"\\\"\\\"\\n{text}\\n\\\"\\\"\\\"\\n\\nReturn only a single JSON object.\"\n",
        "    return system + \"\\n\\n\" + user\n",
        "\n",
        "def _extract_json_from_text(text: str) -> Dict:\n",
        "    m = re.search(r\"(\\{[\\s\\S]*\\})\", text)\n",
        "    if not m:\n",
        "        try:\n",
        "            return json.loads(text)\n",
        "        except Exception:\n",
        "            raise ValueError(\"No JSON found in model output.\")\n",
        "    candidate = m.group(1)\n",
        "    candidate = candidate.replace(\"'\", '\"')\n",
        "    candidate = re.sub(r\",(\\s*[}\\]])\", r\"\\1\", candidate)\n",
        "    return json.loads(candidate)\n",
        "\n",
        "def _call_gemini(text: str, model: str = \"gemini-2.5-flash\", max_output_tokens: Optional[int] = 512) -> Dict:\n",
        "    api_key = os.getenv(\"GEMINI_API_KEY\") or os.getenv(\"GENAI_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise RuntimeError(\"GEMINI_API_KEY not set\")\n",
        "\n",
        "    if not SDK_AVAILABLE:\n",
        "        raise RuntimeError(\"Gemini SDK not available (could not import google.genai)\")\n",
        "\n",
        "    os.environ[\"GENAI_API_KEY\"] = api_key\n",
        "    client = genai.Client()\n",
        "    prompt = _force_json_prompt(text)\n",
        "\n",
        "    # Build generation_config if the SDK exposes it\n",
        "    gen_cfg = None\n",
        "    try:\n",
        "        # Many genai versions provide GenerationConfig\n",
        "        gen_cfg = genai.GenerationConfig(max_output_tokens=max_output_tokens) if max_output_tokens is not None else None\n",
        "    except Exception:\n",
        "        gen_cfg = None\n",
        "\n",
        "    try:\n",
        "        if gen_cfg is not None:\n",
        "            resp = client.models.generate_content(model=model, contents=prompt, generation_config=gen_cfg)\n",
        "        else:\n",
        "            # older/newer SDKs may accept contents and other args without generation_config\n",
        "            resp = client.models.generate_content(model=model, contents=prompt)\n",
        "        raw = getattr(resp, \"text\", None) or str(resp)\n",
        "    except TypeError as te:\n",
        "        # Handle case where generate_content does not accept our args ‚Äî retry with minimal call\n",
        "        try:\n",
        "            resp = client.models.generate_content(model=model, contents=prompt)\n",
        "            raw = getattr(resp, \"text\", None) or str(resp)\n",
        "        except Exception as e2:\n",
        "            raise RuntimeError(f\"Gemini call failed (TypeError branch): {te} / {e2}\")\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"Gemini call failed: {e}\")\n",
        "\n",
        "    # Parse JSON robustly\n",
        "    try:\n",
        "        parsed = json.loads(raw)\n",
        "    except Exception:\n",
        "        parsed = _extract_json_from_text(raw)\n",
        "\n",
        "    # Normalize keys and types\n",
        "    result = {}\n",
        "    for k in EXPECTED_KEYS:\n",
        "        v = parsed.get(k) if isinstance(parsed, dict) else None\n",
        "        if k == \"has_supporting_document\":\n",
        "            if isinstance(v, str):\n",
        "                lv = v.strip().lower()\n",
        "                result[k] = lv in (\"true\", \"yes\", \"1\", \"y\", \"t\")\n",
        "            else:\n",
        "                result[k] = bool(v) if v is not None else False\n",
        "        else:\n",
        "            result[k] = v if v is not None else None\n",
        "\n",
        "    result[\"mode\"] = \"gemini\"\n",
        "    return result\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Public function\n",
        "# -------------------------\n",
        "def extract_leave_data(text: str) -> Dict:\n",
        "    if not text or not text.strip():\n",
        "        return {\"error\": \"Empty text\", \"mode\": \"error\"}\n",
        "\n",
        "    try:\n",
        "        if os.getenv(\"GEMINI_API_KEY\"):\n",
        "            try:\n",
        "                return _call_gemini(text)\n",
        "            except Exception as e:\n",
        "                fallback = _basic_extract(text)\n",
        "                fallback[\"_fallback_reason\"] = f\"gemini_failed: {e}\"\n",
        "                fallback[\"mode\"] = \"local_rule_engine_fallback\"\n",
        "                return fallback\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return _basic_extract(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcCeZ-V-hjLp",
        "outputId": "8f6bcadb-af8b-4132-c15e-a3117c7176db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing backend/ai_extractor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from backend.ai_extractor import extract_leave_data\n",
        "\n",
        "# text = \"Hi, my name is Jay Cutler, I need leaves from 12/12/2025 to 16/12/2025 due to a family function.\"\n",
        "# print(extract_leave_data(text))\n"
      ],
      "metadata": {
        "id": "fk6hwu8XdqtS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Storage System"
      ],
      "metadata": {
        "id": "NcvnK01N_nVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile backend/storage.py\n",
        "import os\n",
        "import csv\n",
        "from datetime import datetime\n",
        "from typing import List, Dict\n",
        "\n",
        "DATA_DIR = \"data\"\n",
        "FILE_PATH = os.path.join(DATA_DIR, \"leave_requests.csv\")\n",
        "\n",
        "COLUMNS = [\n",
        "    \"request_id\",\n",
        "    \"employee_name\",\n",
        "    \"start_date\",\n",
        "    \"end_date\",\n",
        "    \"total_days\",\n",
        "    \"leave_type\",\n",
        "    \"reason\",\n",
        "    \"urgency\",\n",
        "    \"has_supporting_document\",\n",
        "    \"status\",\n",
        "    \"created_at\",\n",
        "    \"_fallback_reason\"\n",
        "]\n",
        "\n",
        "def _ensure_storage():\n",
        "    os.makedirs(DATA_DIR, exist_ok=True)\n",
        "    if not os.path.exists(FILE_PATH):\n",
        "        with open(FILE_PATH, mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "            writer = csv.DictWriter(f, fieldnames=COLUMNS)\n",
        "            writer.writeheader()\n",
        "\n",
        "def save_leave_request(data: Dict) -> str:\n",
        "    _ensure_storage()\n",
        "    request_id = datetime.now().strftime(\"%Y%m%d%H%M%S%f\")\n",
        "    row = {\n",
        "        \"request_id\": request_id,\n",
        "        \"employee_name\": data.get(\"employee_name\"),\n",
        "        \"start_date\": data.get(\"start_date\"),\n",
        "        \"end_date\": data.get(\"end_date\"),\n",
        "        \"total_days\": data.get(\"total_days\"),\n",
        "        \"leave_type\": data.get(\"leave_type\"),\n",
        "        \"reason\": data.get(\"reason\"),\n",
        "        \"urgency\": data.get(\"urgency\"),\n",
        "        \"has_supporting_document\": str(data.get(\"has_supporting_document\")),\n",
        "        \"status\": \"Pending\",\n",
        "        \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
        "        \"_fallback_reason\": data.get(\"_fallback_reason\", \"\")\n",
        "    }\n",
        "    with open(FILE_PATH, mode=\"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=COLUMNS)\n",
        "        writer.writerow(row)\n",
        "    return request_id\n",
        "\n",
        "def load_all_requests() -> List[Dict]:\n",
        "    if not os.path.exists(FILE_PATH):\n",
        "        return []\n",
        "    with open(FILE_PATH, mode=\"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        return list(reader)\n",
        "\n",
        "def update_request_status(request_id: str, new_status: str) -> bool:\n",
        "    _ensure_storage()\n",
        "    if not os.path.exists(FILE_PATH):\n",
        "        return False\n",
        "    with open(FILE_PATH, mode=\"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        rows = list(reader)\n",
        "    found = False\n",
        "    for row in rows:\n",
        "        if row[\"request_id\"] == request_id:\n",
        "            row[\"status\"] = new_status\n",
        "            found = True\n",
        "    if not found:\n",
        "        return False\n",
        "    with open(FILE_PATH, mode=\"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=COLUMNS)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(rows)\n",
        "    return True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAh3RbRPDAA_",
        "outputId": "73187436-9adb-4b3c-a901-4b15e5758ddf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing backend/storage.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "wSZXtbp_99Tf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streamlit Application"
      ],
      "metadata": {
        "id": "-pFZJWMSeE6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import os\n",
        "import requests\n",
        "\n",
        "from backend.ai_extractor import extract_leave_data\n",
        "from backend.storage import save_leave_request, load_all_requests, update_request_status\n",
        "\n",
        "st.set_page_config(page_title=\"SmartLeave AI\", layout=\"wide\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    body { background-color: #F8F9FA; font-family: 'Segoe UI', sans-serif; }\n",
        "    .title { font-size: 32px; font-weight: 700; color: #3A3A3A; margin-bottom: 20px; }\n",
        "    .subtitle { font-size: 20px; font-weight: 600; color: #4A4A4A; margin-top: 30px; }\n",
        "    .card { padding: 20px; background-color: white; border-radius: 10px; margin-bottom: 15px; box-shadow: 0px 1px 6px rgba(0,0,0,0.1); }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "page = st.sidebar.radio(\"Navigation\", [\"Employee - Request\", \"Manager - Dashboard\", \"Analytics\"])\n",
        "\n",
        "# Helper: produce a user-safe view of the analysis (hide internals)\n",
        "def _safe_analysis_for_display(analysis: dict) -> dict:\n",
        "    if not isinstance(analysis, dict):\n",
        "        return {}\n",
        "    return {k: v for k, v in analysis.items() if k not in (\"mode\", \"_fallback_reason\")}\n",
        "\n",
        "# ---------- EMPLOYEE PAGE ----------\n",
        "if page == \"Employee - Request\":\n",
        "\n",
        "    # Helper: produce a user-safe view of the analysis (hide internals)\n",
        "    def _safe_analysis_for_display(analysis: dict) -> dict:\n",
        "        if not isinstance(analysis, dict):\n",
        "            return {}\n",
        "        return {k: v for k, v in analysis.items() if k not in (\"mode\", \"_fallback_reason\")}\n",
        "\n",
        "    st.markdown(\"<div class='title'>Employee Leave Request</div>\", unsafe_allow_html=True)\n",
        "\n",
        "    # Initialize session keys if missing\n",
        "    if \"analysis\" not in st.session_state:\n",
        "        st.session_state[\"analysis\"] = None\n",
        "    if \"support_file\" not in st.session_state:\n",
        "        st.session_state[\"support_file\"] = None\n",
        "\n",
        "    # Inputs\n",
        "    employee_name = st.text_input(\"Employee name:\", key=\"emp_name_input\")\n",
        "    leave_text = st.text_area(\n",
        "        \"Describe your leave request:\",\n",
        "        placeholder=\"Write your leave description with date format dd/mm/yyyy here...\",\n",
        "        height=150,\n",
        "        key=\"leave_text_input\"\n",
        "    )\n",
        "\n",
        "    # Upload: persist into session_state\n",
        "    uploaded = st.file_uploader(\"Upload supporting document (Optional)\", type=[\"pdf\", \"jpg\", \"png\"], key=\"support_file_uploader\")\n",
        "    if uploaded is not None:\n",
        "        st.session_state[\"support_file\"] = uploaded\n",
        "    if uploaded is None and st.session_state.get(\"support_file\") is not None:\n",
        "        st.session_state[\"support_file\"] = None\n",
        "\n",
        "    # -------------------\n",
        "    # ANALYZE button\n",
        "    # -------------------\n",
        "    if st.button(\"Analyze\"):\n",
        "        if not leave_text.strip():\n",
        "            st.error(\"Please enter your leave request description.\")\n",
        "        else:\n",
        "            try:\n",
        "                full_analysis = extract_leave_data(leave_text)\n",
        "                st.session_state[\"analysis\"] = full_analysis\n",
        "                st.success(\"Analysis complete ‚Äî please review the parsed values below.\")\n",
        "            except Exception:\n",
        "                st.session_state[\"analysis\"] = None\n",
        "                st.error(\"Analysis failed. Please try again.\")\n",
        "\n",
        "    # -------------------\n",
        "    # SHOW JSON + CONFIRM FORM\n",
        "    # -------------------\n",
        "    if st.session_state.get(\"analysis\"):\n",
        "        analysis = st.session_state[\"analysis\"]\n",
        "        safe_view = _safe_analysis_for_display(analysis)\n",
        "\n",
        "        if employee_name.strip():\n",
        "          safe_view[\"employee_name\"] = employee_name.strip()\n",
        "\n",
        "        st.markdown(\"**AI Analysis (parsed JSON):**\")\n",
        "        st.json(safe_view)\n",
        "        st.info(\"You may edit the values below before submitting.\")\n",
        "\n",
        "        # Prefill values\n",
        "        pre_name = (employee_name.strip() or analysis.get(\"employee_name\") or \"\")\n",
        "        pre_start = analysis.get(\"start_date\") or \"\"\n",
        "        pre_end = analysis.get(\"end_date\") or \"\"\n",
        "        pre_days = str(analysis.get(\"total_days\") or \"\")\n",
        "        pre_leave = analysis.get(\"leave_type\") or \"Other\"\n",
        "        pre_urgency = analysis.get(\"urgency\") or \"medium\"\n",
        "        pre_reason = analysis.get(\"reason\") or \"\"\n",
        "\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### Confirm & Submit (edit if needed)\")\n",
        "\n",
        "        with st.form(\"confirm_form\"):\n",
        "            name_confirm = st.text_input(\"Employee name (confirm):\", value=pre_name)\n",
        "            start_confirm = st.text_input(\"Start date (YYYY-MM-DD):\", value=pre_start)\n",
        "            end_confirm = st.text_input(\"End date (YYYY-MM-DD):\", value=pre_end)\n",
        "            days_confirm = st.text_input(\"Total days:\", value=pre_days)\n",
        "            leave_confirm = st.selectbox(\n",
        "                \"Leave type:\",\n",
        "                options=[\"Sick Leave\", \"Casual Leave\", \"Paid Leave\", \"Work From Home\", \"Other\"],\n",
        "                index=[\"Sick Leave\", \"Casual Leave\", \"Paid Leave\", \"Work From Home\", \"Other\"].index(pre_leave) if pre_leave in [\"Sick Leave\",\"Casual Leave\",\"Paid Leave\",\"Work From Home\",\"Other\"] else 4\n",
        "            )\n",
        "            urgency_confirm = st.selectbox(\n",
        "                \"Urgency:\",\n",
        "                options=[\"low\",\"medium\",\"high\"],\n",
        "                index=[\"low\",\"medium\",\"high\"].index(pre_urgency) if pre_urgency in [\"low\",\"medium\",\"high\"] else 1\n",
        "            )\n",
        "            reason_confirm = st.text_area(\"Reason (confirm):\", value=pre_reason, height=120)\n",
        "\n",
        "            submit_btn = st.form_submit_button(\"Save Request (confirm)\")\n",
        "\n",
        "            if submit_btn:\n",
        "                # safe parsing of total days\n",
        "                try:\n",
        "                    total_days_val = int(days_confirm) if days_confirm.strip() else None\n",
        "                except ValueError:\n",
        "                    st.error(\"Total days must be an integer.\")\n",
        "                    st.stop()\n",
        "\n",
        "                uploaded_file = st.session_state.get(\"support_file\")\n",
        "                has_supporting_document = uploaded_file is not None\n",
        "\n",
        "                payload = {\n",
        "                    \"employee_name\": name_confirm.strip() or None,\n",
        "                    \"start_date\": start_confirm.strip() or None,\n",
        "                    \"end_date\": end_confirm.strip() or None,\n",
        "                    \"total_days\": total_days_val,\n",
        "                    \"leave_type\": leave_confirm,\n",
        "                    \"reason\": reason_confirm.strip(),\n",
        "                    \"urgency\": urgency_confirm,\n",
        "                    \"has_supporting_document\": has_supporting_document,\n",
        "                }\n",
        "\n",
        "                if analysis.get(\"_fallback_reason\"):\n",
        "                    payload[\"_fallback_reason\"] = analysis[\"_fallback_reason\"]\n",
        "\n",
        "                try:\n",
        "                    request_id = save_leave_request(payload)\n",
        "                    st.success(\"Request submitted successfully!\")\n",
        "                except Exception as e:\n",
        "                    st.error(f\"Failed to save request: {e}\")\n",
        "                    st.stop()\n",
        "\n",
        "                # Notify n8n without internal fields\n",
        "                webhook_payload = {k: v for k, v in payload.items() if k != \"_fallback_reason\"}\n",
        "                try:\n",
        "                    WEBHOOK_URL = os.getenv(\"N8N_WEBHOOK_URL\", \"https://leaverequestn8n.app.n8n.cloud/webhook/smartleave\")\n",
        "                    requests.post(WEBHOOK_URL, json={\"event_type\": \"new_request\", \"request_id\": request_id, **webhook_payload}, timeout=5)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "                st.session_state[\"analysis\"] = None\n",
        "                st.info(\"Saved ‚Äî open Manager or Analytics to view the request.\")\n",
        "\n",
        "# ---------- MANAGER PAGE ----------\n",
        "elif page == \"Manager - Dashboard\":\n",
        "    st.markdown(\"<div class='title'>Manager Dashboard</div>\", unsafe_allow_html=True)\n",
        "    requests_list = load_all_requests()\n",
        "    if not requests_list:\n",
        "        st.info(\"No leave requests found.\")\n",
        "    else:\n",
        "        df = pd.DataFrame(requests_list)\n",
        "        # Hide internal debug column from UI if present\n",
        "        if \"_fallback_reason\" in df.columns:\n",
        "            df = df.drop(columns=[\"_fallback_reason\"])\n",
        "\n",
        "        with st.expander(\"üîç Filter Requests\", expanded=True):\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                status_filter = st.selectbox(\"Status\", [\"All\", \"Pending\", \"Approved\", \"Rejected\"])\n",
        "            with col2:\n",
        "                leave_filter = st.selectbox(\"Leave Type\", [\"All\"] + sorted(df[\"leave_type\"].dropna().unique().tolist()))\n",
        "            with col3:\n",
        "                urgency_filter = st.selectbox(\"Urgency\", [\"All\"] + sorted(df[\"urgency\"].dropna().unique().tolist()))\n",
        "\n",
        "        filtered_df = df.copy()\n",
        "        if status_filter != \"All\":\n",
        "            filtered_df = filtered_df[filtered_df[\"status\"] == status_filter]\n",
        "        if leave_filter != \"All\":\n",
        "            filtered_df = filtered_df[filtered_df[\"leave_type\"] == leave_filter]\n",
        "        if urgency_filter != \"All\":\n",
        "            filtered_df = filtered_df[filtered_df[\"urgency\"] == urgency_filter]\n",
        "\n",
        "        st.markdown(\"<div class='subtitle'>All Leave Requests</div>\", unsafe_allow_html=True)\n",
        "        st.dataframe(filtered_df, use_container_width=True)\n",
        "\n",
        "        st.markdown(\"<div class='subtitle'>Approve or Reject Request</div>\", unsafe_allow_html=True)\n",
        "        req_id = st.text_input(\"Enter Request ID:\")\n",
        "        action = st.radio(\"Choose Action:\", [\"Approve\", \"Reject\"])\n",
        "        if st.button(\"Submit Action\"):\n",
        "            if not req_id.strip():\n",
        "                st.error(\"Please enter a request ID.\")\n",
        "            else:\n",
        "                new_status = \"Approved\" if action == \"Approve\" else \"Rejected\"\n",
        "                updated = update_request_status(req_id, new_status)\n",
        "                if updated:\n",
        "                    st.success(f\"Request {req_id} updated to {new_status}!\")\n",
        "                    updated_requests = load_all_requests()\n",
        "                    df_updated = pd.DataFrame(updated_requests)\n",
        "                    # Hide internal debug column\n",
        "                    if \"_fallback_reason\" in df_updated.columns:\n",
        "                        df_updated = df_updated.drop(columns=[\"_fallback_reason\"])\n",
        "                    row_match = df_updated[df_updated[\"request_id\"] == req_id]\n",
        "                    if not row_match.empty:\n",
        "                        row = row_match.iloc[0]\n",
        "                        payload = {\n",
        "                            \"event_type\": \"status_update\",\n",
        "                            \"request_id\": req_id,\n",
        "                            \"status\": new_status,\n",
        "                            \"employee_name\": row[\"employee_name\"],\n",
        "                            \"start_date\": row[\"start_date\"],\n",
        "                            \"end_date\": row[\"end_date\"],\n",
        "                            \"total_days\": row[\"total_days\"],\n",
        "                            \"leave_type\": row[\"leave_type\"],\n",
        "                        }\n",
        "                        WEBHOOK_URL = os.getenv(\"N8N_WEBHOOK_URL\", \"https://leaverequestn8n.app.n8n.cloud/webhook/smartleave\")\n",
        "                        try:\n",
        "                            requests.post(WEBHOOK_URL, json=payload, timeout=5)\n",
        "                        except Exception as e:\n",
        "                            st.warning(f\"Could not notify employee via n8n: {e}\")\n",
        "                    else:\n",
        "                        st.warning(\"Could not find request details for this ID in storage.\")\n",
        "                else:\n",
        "                    st.error(\"Invalid request ID.\")\n",
        "\n",
        "# ---------- ANALYTICS PAGE ----------\n",
        "elif page == \"Analytics\":\n",
        "    st.markdown(\"<div class='title'>Analytics</div>\", unsafe_allow_html=True)\n",
        "\n",
        "    requests_list = load_all_requests()\n",
        "    if not requests_list:\n",
        "        st.info(\"Not enough data for analytics.\")\n",
        "    else:\n",
        "        df = pd.DataFrame(requests_list)\n",
        "\n",
        "        # --- Basic cleanup & safe conversions ---\n",
        "        # hide internal debug column if present\n",
        "        if \"_fallback_reason\" in df.columns:\n",
        "            df = df.drop(columns=[\"_fallback_reason\"])\n",
        "\n",
        "        # Ensure expected columns exist (avoid KeyError)\n",
        "        for c in [\"created_at\", \"total_days\", \"has_supporting_document\", \"status\", \"leave_type\"]:\n",
        "            if c not in df.columns:\n",
        "                df[c] = None\n",
        "\n",
        "        # created_at -> datetime (coerce errors to NaT)\n",
        "        df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], errors=\"coerce\")\n",
        "\n",
        "        # total_days -> numeric (coerce non-numeric to NaN)\n",
        "        df[\"total_days\"] = pd.to_numeric(df[\"total_days\"], errors=\"coerce\")\n",
        "\n",
        "        # has_supporting_document -> boolean (stored as 'True'/'False' strings earlier)\n",
        "        # Map common string forms to True/False; fallback False\n",
        "        df[\"has_supporting_document\"] = (\n",
        "            df[\"has_supporting_document\"]\n",
        "            .astype(str)\n",
        "            .str.strip()\n",
        "            .str.lower()\n",
        "            .map({\"true\": True, \"false\": False, \"none\": False, \"nan\": False})\n",
        "            .fillna(False)\n",
        "        )\n",
        "\n",
        "        # status, leave_type: fill missing with \"Unknown\"\n",
        "        df[\"status\"] = df[\"status\"].fillna(\"Unknown\")\n",
        "        df[\"leave_type\"] = df[\"leave_type\"].fillna(\"Unknown\")\n",
        "\n",
        "        # --- KPIs ---\n",
        "        total_requests = len(df)\n",
        "        pending_count = int((df[\"status\"] == \"Pending\").sum())\n",
        "        approved_count = int((df[\"status\"] == \"Approved\").sum())\n",
        "        rejected_count = int((df[\"status\"] == \"Rejected\").sum())\n",
        "        avg_days = df[\"total_days\"].dropna().mean()\n",
        "        pct_with_docs = (df[\"has_supporting_document\"].mean() * 100) if total_requests > 0 else 0\n",
        "\n",
        "        k1, k2, k3, k4, k5 = st.columns(5)\n",
        "        k1.metric(\"Total requests\", f\"{total_requests}\")\n",
        "        k2.metric(\"Pending\", f\"{pending_count}\")\n",
        "        k3.metric(\"Approved\", f\"{approved_count}\")\n",
        "        k4.metric(\"Rejected\", f\"{rejected_count}\")\n",
        "        k5.metric(\"Avg days (reported)\", f\"{avg_days:.2f}\" if not pd.isna(avg_days) else \"‚Äî\")\n",
        "\n",
        "        st.markdown(f\"**% with supporting document:** {pct_with_docs:.1f}%\")\n",
        "\n",
        "        # --- Visualizations ---\n",
        "        st.markdown(\"<div class='subtitle'>Leave Type Distribution</div>\", unsafe_allow_html=True)\n",
        "        # chart needs a Series indexed by label\n",
        "        type_counts = df[\"leave_type\"].value_counts()\n",
        "        st.bar_chart(type_counts)\n",
        "\n",
        "        st.markdown(\"<div class='subtitle'>Status Distribution</div>\", unsafe_allow_html=True)\n",
        "        st.bar_chart(df[\"status\"].value_counts())\n",
        "\n",
        "        st.markdown(\"<div class='subtitle'>Requests Over Time</div>\", unsafe_allow_html=True)\n",
        "        # group by date (created_at may be NaT; drop those rows for the timeseries)\n",
        "        ts = df.dropna(subset=[\"created_at\"]).groupby(df[\"created_at\"].dt.date).size().sort_index()\n",
        "        if not ts.empty:\n",
        "            st.line_chart(ts)\n",
        "        else:\n",
        "            st.info(\"No timestamped requests to plot over time.\")\n",
        "\n",
        "        # --- Recent requests table for inspection ---\n",
        "        st.markdown(\"<div class='subtitle'>Recent Requests</div>\", unsafe_allow_html=True)\n",
        "        # show last 10 requests sorted by created_at if present, else by insertion order\n",
        "        try:\n",
        "            recent = df.sort_values(by=\"created_at\", ascending=False).head(10)\n",
        "        except Exception:\n",
        "            recent = df.tail(10)\n",
        "        # Keep columns readable/order them\n",
        "        display_cols = [\"request_id\", \"employee_name\", \"start_date\", \"end_date\", \"total_days\", \"leave_type\", \"urgency\", \"status\", \"has_supporting_document\", \"created_at\"]\n",
        "        display_cols = [c for c in display_cols if c in recent.columns]\n",
        "        st.dataframe(recent[display_cols].reset_index(drop=True), use_container_width=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Com6qpgcO9Vs",
        "outputId": "7cdd44a7-d14c-4f0a-ac3d-18f90054b414"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Application"
      ],
      "metadata": {
        "id": "I_IuifDM-OkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ensure dependencies\n",
        "!pip install --quiet streamlit pyngrok python-dotenv google-generativeai\n",
        "\n",
        "# kill old streamlit\n",
        "!pkill -f streamlit || echo \"No streamlit\"\n",
        "\n",
        "# start streamlit\n",
        "!streamlit run app.py --server.port 8501 &>/dev/null &\n",
        "\n",
        "# setup ngrok\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "ngrok.set_auth_token(\"36TiRiENjPUlO8uo6FM1bls4QCB_4AjAyFcDWQdbL8bCgLy5X\")\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "public_url\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBZ0DvnWGe7Z",
        "outputId": "8427005c-4bf0-4b10-9b50-877d0d4b1370"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<NgrokTunnel: \"https://geodetically-formulaic-del.ngrok-free.dev\" -> \"http://localhost:8501\">"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "WRrBp_X2IAL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pkill -f streamlit || echo \"No existing streamlit process\"\n",
        "# !streamlit run app.py --server.port 8501\n"
      ],
      "metadata": {
        "id": "0NGzK3G6zPqs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from backend.ai_extractor import extract_leave_data\n",
        "\n",
        "# text = \"Hi, my name is Jay Cutler, I need leaves from 12/12/2025 to 16/12/2025, reason being family function.\"\n",
        "# print(extract_leave_data(text))\n"
      ],
      "metadata": {
        "id": "3OkPNXQMoSpC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "glp6e-FuHXaL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import requests, json\n",
        "\n",
        "# WEBHOOK_URL = \"https://leaverequestn8n.app.n8n.cloud/webhook/smartleave\"  # n8n Webhook node ka Production URL\n",
        "\n",
        "# payload = {\n",
        "#     \"event_type\": \"new_request\",\n",
        "#     \"employee_name\": \"Debug Tester\",\n",
        "#     \"request_id\": \"TEST-123\",\n",
        "#     \"start_date\": \"2025-12-10\",\n",
        "#     \"end_date\": \"2025-12-12\",\n",
        "#     \"total_days\": 3,\n",
        "#     \"leave_type\": \"Sick Leave\",\n",
        "#     \"reason\": \"debug test\",\n",
        "#     \"urgency\": \"medium\",\n",
        "#     \"status\": \"Pending\"\n",
        "# }\n",
        "\n",
        "# res = requests.post(WEBHOOK_URL, json=payload)\n",
        "# print(\"Status:\", res.status_code)\n",
        "# print(\"Text:\", res.text[:200])\n"
      ],
      "metadata": {
        "id": "Mx_3FdNUHYfZ"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}